{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dadb36f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'recursos'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Este c√≥digo est√° INTENCIONALMENTE mal hecho para mostrar errores comunes\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrecursos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_data\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'recursos'"
     ]
    }
   ],
   "source": [
    "# Este c√≥digo est√° INTENCIONALMENTE mal hecho para mostrar errores comunes\n",
    "\n",
    "from recursos.utils import load_data\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "# Para importar utils desde recursos\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "\n",
    "# Cargar datos usando utilidad centralizada\n",
    "df = load_data('credit_scoring.csv')\n",
    "\n",
    "# Configuraci√≥n real del dataset\n",
    "TARGET_COL = 'target_y'\n",
    "\n",
    "print(f\"Dimensiones: {df.shape}\")\n",
    "print(f\"Columnas disponibles: {df.columns.tolist()[:5]}...\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5818efca",
   "metadata": {},
   "source": [
    "### üìÇ Diccionario de Datos (Credit Scoring)\n",
    "Estamos trabajando con un dataset real de **Riesgo de Cr√©dito para Empresas**.\n",
    "El objetivo es predecir si una empresa caer√° en incumplimiento de pago (`target_y = 1`) en los pr√≥ximos meses.\n",
    "\n",
    "**Variables Clave:**\n",
    "*   `target_y`: **Variable Objetivo**. 1 = Cliente Incumplidor (Bad), 0 = Cliente Cumplidor (Good).\n",
    "*   `banca`, `sector_final`: Segmentaci√≥n del cliente (Categ√≥ricas).\n",
    "*   `NumeroTrabajadores`: Tama√±o de la empresa.\n",
    "*   `MAX_PORC_DEUDA...`: Variables de comportamiento financiero en el sistema (Deuda, Sobregiros).\n",
    "*   `EF_...`: Variables de Estados Financieros (Ratios de liquidez, rotaci√≥n, etc.).\n",
    "*   `periodo`: Mes de la evaluaci√≥n (YYYYMM).\n",
    "\n",
    "*Nota: Este dataset contiene valores nulos, columnas irrelevantes (como `Unnamed: 0`) y tipos de datos mezclados, lo cual es perfecto para nuestra \"Galer√≠a de los Horrores\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a96212e",
   "metadata": {},
   "source": [
    "### 1. Limpieza Manual (El problema de la repetibilidad)\n",
    "Aqu√≠ empezamos a \"parchar\" los datos manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175c6aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è ANTI-PATTERN: Llenar nulos usando estad√≠sticas de TODO el dataset\n",
    "# Problema: Estamos usando la media de TODO el dataset (incluyendo lo que ser√° test) -> Data Leakage\n",
    "\n",
    "# Identificar columnas num√©ricas con nulos\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "cols_with_nulls = df[numeric_cols].columns[df[numeric_cols].isnull().any()\n",
    "                                           ].tolist()\n",
    "print(f\"Columnas con nulos: {cols_with_nulls[:3]}...\")\n",
    "\n",
    "# DEMOSTRACI√ìN DEL LEAKAGE\n",
    "col_ejemplo = 'NumeroTrabajadores'\n",
    "\n",
    "# TODO: Calcula la media global de la columna 'col_ejemplo' usando TODO el dataframe (df)\n",
    "# media_global = ...\n",
    "\n",
    "# Simulamos un split correcto solo para comparar (NO MODIFICAR ESTA PARTE)\n",
    "if col_ejemplo in df.columns:\n",
    "    train_real, test_real = train_test_split(\n",
    "        df[col_ejemplo], test_size=0.2, random_state=42)\n",
    "    media_train_real = train_real.mean()\n",
    "\n",
    "    # Descomenta las siguientes l√≠neas cuando hayas calculado media_global\n",
    "    # print(f\"\\n--- üïµÔ∏è‚Äç‚ôÄÔ∏è Detectando el Leakage en '{col_ejemplo}' ---\")\n",
    "    # print(f\"Media Global (Trampa): {media_global:.2f}\")\n",
    "    # print(f\"Media Train Real:      {media_train_real:.2f}\")\n",
    "    # print(f\"Diferencia (Info del futuro): {abs(media_global - media_train_real):.2f}\")\n",
    "\n",
    "# MALO: Llenar con la media de TODO el dataset\n",
    "for col in cols_with_nulls:\n",
    "    # TODO: Calcula la media de la columna actual 'col'\n",
    "    # mean_val = ...\n",
    "\n",
    "    # TODO: Rellena los nulos de la columna 'col' con 'mean_val' usando .fillna()\n",
    "    # df[col] = ...\n",
    "    pass  # Eliminar este pass cuando completes el c√≥digo\n",
    "\n",
    "# Borrar filas con nulos restantes (sin criterio claro)\n",
    "df = df.dropna()\n",
    "print(f\"\\nDimensiones post-limpieza: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007647b1",
   "metadata": {},
   "source": [
    "### üß† Micro-Desaf√≠o: Reflexi√≥n\n",
    "¬øPor qu√© crees que usar la media de **TODO** el dataset para imputar valores es un problema grave?\n",
    "\n",
    "*Pista: Imagina que el dataset de test tiene valores muy diferentes a los de train. Al usar la media global, ¬øest√°s \"espiando\" el futuro?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f4e49",
   "metadata": {},
   "source": [
    "### 2. Encoding Manual (El problema de la dimensionalidad)\n",
    "Usamos `get_dummies` en todo el dataset antes de dividir. ¬°Peligro!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f563ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una variable categ√≥rica de ejemplo basada en una columna num√©rica existente\n",
    "# Usamos 'ANTIGUEDAD_RCC_01M' como proxy\n",
    "num_credit_col = 'ANTIGUEDAD_RCC_01M'\n",
    "if num_credit_col in df.columns:\n",
    "    df['Rango_Credito'] = pd.cut(\n",
    "        df[num_credit_col], bins=[-1, 25, 40, 100], labels=['Bajo', 'Medio', 'Alto'])\n",
    "else:\n",
    "    # Crear variable dummy si no existe la columna\n",
    "    df['Rango_Credito'] = pd.Series(\n",
    "        ['Bajo', 'Medio', 'Alto']*(len(df)//3 + 1))[:len(df)]\n",
    "\n",
    "# One-Hot Encoding global\n",
    "# Problema: Si en el futuro llega un dato con una categor√≠a nueva, esto rompe.\n",
    "\n",
    "# TODO: Aplica pd.get_dummies al dataframe 'df' sobre la columna 'Rango_Credito'\n",
    "# df = ...\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feced4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üí• DEMOSTRACI√ìN DE FRAGILIDAD EN PRODUCCI√ìN\n",
    "# Imaginemos que ya entrenamos el modelo y llega un NUEVO cliente para ser evaluado.\n",
    "# Este cliente tiene 'Rango_Credito' = 'Bajo'.\n",
    "\n",
    "print(\"--- üè≠ Simulando Producci√≥n ---\")\n",
    "\n",
    "# 1. Llega el cliente\n",
    "nuevo_cliente = pd.DataFrame({'Rango_Credito': ['Bajo']})\n",
    "\n",
    "# 2. Aplicamos la MISMA l√≥gica manual (get_dummies)\n",
    "# TODO: Aplica pd.get_dummies a 'nuevo_cliente' especificando columns=['Rango_Credito']\n",
    "# nuevo_cliente_encoded = ...\n",
    "\n",
    "# 3. ¬øQu√© columnas espera el modelo vs qu√© columnas tenemos?\n",
    "# (Asumimos que el modelo se entren√≥ con el df completo de arriba)\n",
    "columnas_esperadas = [col for col in df.columns if 'Rango_Credito' in col]\n",
    "\n",
    "# Descomenta las siguientes l√≠neas cuando hayas completado el paso 2\n",
    "# columnas_obtenidas = nuevo_cliente_encoded.columns.tolist()\n",
    "\n",
    "# print(f\"Columnas que el modelo espera: {columnas_esperadas}\")\n",
    "# print(f\"Columnas que gener√≥ el nuevo cliente: {columnas_obtenidas}\")\n",
    "\n",
    "# if len(columnas_esperadas) != len(columnas_obtenidas):\n",
    "#     print(\"\\nüö® ¬°CRASH! El modelo fallar√° porque el n√∫mero de features no coincide.\")\n",
    "#     print(\"El modelo espera columnas para 'Medio' y 'Alto' (con valor 0), pero get_dummies no las cre√≥.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efcbe19",
   "metadata": {},
   "source": [
    "### 3. Split y Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896614c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è ANTI-PATTERN: Dejar columnas ID o √≠ndices\n",
    "# \"Unnamed: 0\" es solo el √≠ndice de la fila. ¬°No predice nada!\n",
    "# Pero el modelo podr√≠a memorizarlo.\n",
    "# Dejamos 'Unnamed: 0' a prop√≥sito\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "COLS_TO_DROP = [TARGET_COL, 'malo_sf_inicio', 'periodo']\n",
    "\n",
    "# Preparar features y target\n",
    "cols_to_drop_existing = [col for col in COLS_TO_DROP if col in df.columns]\n",
    "X = df.drop(cols_to_drop_existing, axis=1)\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "# Asegurar solo num√©ricas\n",
    "X = X.select_dtypes(include=['int64', 'float64', 'uint8'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# --- COMPARACI√ìN: CON VS SIN ESCALADO ---\n",
    "\n",
    "# 1. ‚ùå EL ERROR: Sin Escalar\n",
    "print(\"--- üî¥ Modelo Sin Escalar ---\")\n",
    "start = time.time()\n",
    "\n",
    "# TODO: Instancia un LogisticRegression con max_iter=100\n",
    "# model_bad = ...\n",
    "\n",
    "# TODO: Entrena el modelo con X_train e y_train\n",
    "# model_bad.fit(..., ...)\n",
    "\n",
    "time_bad = time.time() - start\n",
    "\n",
    "# TODO: Calcula el accuracy en test\n",
    "# acc_bad = accuracy_score(y_test, model_bad.predict(X_test))\n",
    "# print(f\"Tiempo: {time_bad:.4f}s | Accuracy: {acc_bad:.4f}\")\n",
    "\n",
    "# 2. ‚úÖ LA SOLUCI√ìN: Con StandardScaler\n",
    "print(\"\\n--- üü¢ Modelo Escalado (StandardScaler) ---\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# TODO: Ajusta el scaler a X_train y transforma X_train\n",
    "# X_train_scaled = ...\n",
    "\n",
    "# TODO: Transforma X_test usando el scaler ya ajustado (¬°NO fit!)\n",
    "# X_test_scaled = ...\n",
    "\n",
    "start = time.time()\n",
    "model_good = LogisticRegression(max_iter=100)  # Mismas iteraciones\n",
    "model_good.fit(X_train_scaled, y_train)\n",
    "time_good = time.time() - start\n",
    "acc_good = accuracy_score(y_test, model_good.predict(X_test_scaled))\n",
    "print(f\"Tiempo: {time_good:.4f}s | Accuracy: {acc_good:.4f}\")\n",
    "\n",
    "# Comparaci√≥n Visual (Descomentar cuando tengas acc_bad y acc_good)\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.bar(['Sin Escalar', 'Con Scaling'], [acc_bad, acc_good], color=['red', 'green'])\n",
    "# plt.title(\"Accuracy (con pocas iteraciones)\")\n",
    "# plt.ylim(0, 1)\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.bar(['Sin Escalar', 'Con Scaling'], [time_bad, time_good], color=['red', 'green'])\n",
    "# plt.title(\"Tiempo de Entrenamiento (s)\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f0526c",
   "metadata": {},
   "source": [
    "### 4. El Olvido del Escalado (Anti-Pattern)\n",
    "¬øViste la diferencia? üò≤\n",
    "\n",
    "*   **Sin Escalar:** El modelo lanza `ConvergenceWarning`, tarda m√°s (o falla) y tiene peor accuracy porque no logra encontrar el m√≠nimo global.\n",
    "*   **Con Escalar:** El modelo converge r√°pido y feliz.\n",
    "\n",
    "Esto pasa porque la Regresi√≥n Log√≠stica intenta encontrar el camino m√°s r√°pido hacia el m√≠nimo error, pero el terreno es muy irregular:\n",
    "*   `MonthlyIncome` tiene valores de 10,000.\n",
    "*   `age` tiene valores de 50.\n",
    "*   `Rango_Credito_Alto` tiene valores de 0 o 1.\n",
    "\n",
    "Sin **StandardScaler**, el algoritmo da pasos gigantes en una direcci√≥n y diminutos en otra.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Evaluar en Train (El Auto-Enga√±o)\n",
    "A veces, usamos modelos muy potentes (como √Årboles de Decisi√≥n profundos) que tienen una memoria fotogr√°fica.\n",
    "Si evaluamos solo en Train, pensaremos que somos genios... hasta que salimos a producci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4201e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# ‚ö†Ô∏è ANTI-PATTERN: Usar un modelo complejo sin restricciones y evaluar solo en Train\n",
    "# Usamos un √Årbol de Decisi√≥n profundo, que es propenso a memorizar datos\n",
    "# (Cambiamos de LogisticRegression a DecisionTree para ilustrar mejor el overfitting)\n",
    "\n",
    "# TODO: Instancia un DecisionTreeClassifier con random_state=42 (sin limitar profundidad)\n",
    "# overfit_model = ...\n",
    "\n",
    "# TODO: Entrena el modelo con X_train e y_train\n",
    "# overfit_model.fit(..., ...)\n",
    "\n",
    "# Evaluamos\n",
    "# TODO: Predice sobre X_train y calcula accuracy\n",
    "# train_acc = ...\n",
    "\n",
    "# TODO: Predice sobre X_test y calcula accuracy\n",
    "# test_acc = ...\n",
    "\n",
    "# print(f\"Accuracy en Train: {train_acc:.4f} (¬°Perfecto! üòç)\")\n",
    "# print(f\"Accuracy en Test:  {test_acc:.4f} (¬°Desastre! üò≠)\")\n",
    "\n",
    "# Gr√°fico del Auto-Enga√±o (Descomentar al final)\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# bars = plt.bar(['Train (Ilusi√≥n)', 'Test (Realidad)'], [train_acc, test_acc], color=['#2ecc71', '#e74c3c'])\n",
    "# plt.title(\"El Auto-Enga√±o del Overfitting (Decision Tree sin l√≠mites)\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.ylim(0, 1.1)\n",
    "\n",
    "# # Poner valores en las barras\n",
    "# for bar in bars:\n",
    "#     height = bar.get_height()\n",
    "#     plt.text(bar.get_x() + bar.get_width()/2., height, f'{height:.2%}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b77751",
   "metadata": {},
   "source": [
    "### üíÄ Resumen de Horrores (Lo que acabamos de ver)\n",
    "1. **Data Leakage:** Calculamos la media de `MonthlyIncome` usando TODO el dataset (incluyendo test). El modelo \"vio\" informaci√≥n del test set durante el preprocesamiento.\n",
    "2. **Irreproducible:** Si llega un nuevo cliente ma√±ana, ¬øc√≥mo llenamos sus nulos? ¬øTenemos que volver a calcular la media manual y pegarla en el c√≥digo?\n",
    "3. **Fragilidad:** Si el nuevo cliente tiene una categor√≠a de edad que no estaba antes, `get_dummies` fallar√° o crear√° columnas distintas a las que el modelo espera.\n",
    "4. **No Escalar:** Los modelos lineales fallan o tardan una eternidad si las variables tienen escalas muy distintas.\n",
    "5. **IDs como Features:** Dejamos `Unnamed: 0`. Si los datos est√°n ordenados por fecha o target, el modelo aprender√° que \"ID > 10000 es fraude\", lo cual no sirve en producci√≥n.\n",
    "6. **Evaluar en Train:** Creer que un accuracy del 100% en train significa que el modelo es bueno, cuando en realidad solo memoriz√≥ los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa96ed6d",
   "metadata": {},
   "source": [
    "### üìö Otros Anti-Patterns Famosos (Lectura Recomendada)\n",
    "Adem√°s de los que hemos visto en c√≥digo, existen otros patrones peligrosos documentados en la industria (especialmente en el paper cl√°sico de Google *\"Hidden Technical Debt in Machine Learning Systems\"*):\n",
    "\n",
    "1.  **Glue Code (C√≥digo Pegamento):**\n",
    "    *   **Problema:** Tener un sistema donde el 95% del c√≥digo es solo para mover datos de un lado a otro y solo el 5% es ML. Hace que el sistema sea r√≠gido y dif√≠cil de cambiar.\n",
    "    *   üîó [Referencia: Hidden Technical Debt](https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)\n",
    "\n",
    "2.  **Training-Serving Skew (Desviaci√≥n Entrenamiento-Servicio):**\n",
    "    *   **Problema:** Las transformaciones de datos en entrenamiento (ej. Python/Pandas en Jupyter) son diferentes a las de producci√≥n (ej. C++/Java en tiempo real). Esto causa que el modelo prediga basura en producci√≥n aunque funcione bien en el notebook.\n",
    "    *   üîó [Referencia: Google ML Guide](https://developers.google.com/machine-learning/guides/rules-of-ml#training-serving_skew)\n",
    "\n",
    "3.  **Feedback Loops (Bucles de Retroalimentaci√≥n):**\n",
    "    *   **Problema:** El modelo influye en los datos que se generar√°n para el futuro entrenamiento.\n",
    "    *   *Ejemplo:* Un sistema de recomendaci√≥n sugiere videos. Los usuarios hacen clic en ellos. El modelo se re-entrena con esos clics y se vuelve m√°s sesgado hacia lo que ya recomend√≥, ignorando contenido nuevo.\n",
    "\n",
    "4.  **Correction Cascades (Cascadas de Correcci√≥n):**\n",
    "    *   **Problema:** Entrenar un modelo $M_a$ para corregir los errores de un modelo $M_b$. Si cambias $M_b$, rompes $M_a$. Crea una dependencia muy fuerte y dif√≠cil de mantener.\n",
    "\n",
    "5.  **Undeclared Consumers (Consumidores No Declarados):**\n",
    "    *   **Problema:** La salida de tu modelo es usada por otro equipo/sistema sin que lo sepas. Si actualizas tu modelo o cambias el formato de salida, rompes el sistema de alguien m√°s silenciosamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66280c4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöë ¬øC√≥mo arreglamos esto?\n",
    "La respuesta est√° en la **Ingenier√≠a de Software aplicada al ML**:\n",
    "*   Usar **Pipelines** para encapsular la l√≥gica.\n",
    "*   Usar **ColumnTransformer** para aplicar transformaciones espec√≠ficas.\n",
    "*   Usar **Split** ANTES de cualquier c√°lculo.\n",
    "\n",
    "üëâ **Ve al siguiente notebook para ver la soluci√≥n:** `02_Pipelines_y_Baselines.ipynb` üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
