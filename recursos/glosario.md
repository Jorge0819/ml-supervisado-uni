#  Glosario de T茅rminos - Machine Learning Supervisado

## A
*   **Accuracy (Exactitud):** Proporci贸n de predicciones correctas sobre el total. Cuidado: enga帽osa en datasets desbalanceados.
*   **AUC-ROC:** rea bajo la curva ROC. Mide la capacidad del modelo para distinguir entre clases. 0.5 es azar, 1.0 es perfecto.

## B
*   **Bagging (Bootstrap Aggregating):** T茅cnica de ensamble que entrena m煤ltiples modelos en subconjuntos aleatorios de datos (con reemplazo) y promedia sus resultados. Ejemplo: Random Forest.
*   **Bias (Sesgo):** Error debido a suposiciones err贸neas en el algoritmo (ej. asumir linealidad cuando no la hay). Alto bias -> Underfitting.
*   **Boosting:** T茅cnica de ensamble secuencial donde cada modelo intenta corregir los errores del anterior. Ejemplo: XGBoost, LightGBM.

## C
*   **Cross-Validation (Validaci贸n Cruzada):** T茅cnica para evaluar modelos dividiendo la data en K partes (folds) y rotando entrenamiento/validaci贸n.

## D
*   **Data Leakage (Fuga de Datos):** Cuando informaci贸n del target se filtra en las features de entrenamiento, creando modelos optimistas que fallan en producci贸n.

## F
*   **Feature Engineering:** El arte de crear nuevas variables a partir de las existentes para mejorar el modelo.
*   **F1-Score:** Media arm贸nica entre Precision y Recall. til para clases desbalanceadas.

## H
*   **Hiperpar谩metro:** Configuraci贸n externa del modelo que no se aprende de los datos (ej. profundidad del 谩rbol, learning rate).

## O
*   **Optuna:** Framework de optimizaci贸n de hiperpar谩metros que usa b煤squeda bayesiana.
*   **Overfitting (Sobreajuste):** Cuando el modelo memoriza el ruido del set de entrenamiento y falla en datos nuevos.

## P
*   **Pipeline:** Cadena de pasos de procesamiento (limpieza, transformaci贸n, modelo) encapsulada en un solo objeto.
*   **Precision:** De los que predije positivos, 驴cu谩ntos lo eran realmente? (Calidad).

## R
*   **Recall (Sensibilidad):** De todos los positivos reales, 驴cu谩ntos detect茅? (Cantidad).
*   **Regularizaci贸n:** T茅cnica para penalizar la complejidad del modelo y evitar overfitting (L1/Lasso, L2/Ridge).

## S
*   **SHAP (SHapley Additive exPlanations):** M茅todo basado en teor铆a de juegos para explicar la contribuci贸n de cada feature a una predicci贸n.
*   **Stratified K-Fold:** Validaci贸n cruzada que mantiene la proporci贸n de clases en cada fold.

## T
*   **Target Encoding:** Reemplazar una categor铆a por el promedio del target para esa categor铆a. Riesgo alto de leakage.

## U
*   **Underfitting:** Cuando el modelo es demasiado simple para capturar el patr贸n de los datos.

## V
*   **Variance (Varianza):** Sensibilidad del modelo a peque帽os cambios en los datos de entrenamiento. Alta varianza -> Overfitting.
