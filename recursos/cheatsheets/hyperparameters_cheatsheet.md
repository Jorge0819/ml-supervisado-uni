# 游꺕 Cheatsheet: Hiperpar치metros de 츼rboles (XGBoost / LightGBM / RF)

## 游 Random Forest (Bagging)
*Objetivo: Reducir Varianza (Overfitting)*

| Par치metro (sklearn) | Significado | Efecto al Aumentar | Valor T칤pico |
|---|---|---|---|
| `n_estimators` | N칰mero de 치rboles | Mejor estabilidad, m치s lento. No causa overfitting. | 100 - 1000 |
| `max_depth` | Profundidad m치xima | M치s complejidad, riesgo de overfitting. | 10 - None |
| `min_samples_leaf` | M칤nimo de muestras por hoja | Suaviza el modelo (Regularizaci칩n). | 1 - 50 |
| `max_features` | Features por split | Menor valor = 츼rboles m치s diversos (menos correlacionados). | 'sqrt' o 'log2' |

---

## 游 XGBoost / LightGBM (Boosting)
*Objetivo: Reducir Bias y Varianza*

| Par치metro (LGBM / XGB) | Significado | Efecto | Rango T칤pico |
|---|---|---|---|
| `learning_rate` (eta) | Velocidad de aprendizaje | **Bajo:** M치s robusto, requiere m치s 치rboles. **Alto:** R치pido, riesgo overfitting. | 0.01 - 0.3 |
| `n_estimators` (num_boost_round) | N칰mero de iteraciones | Debe ajustarse con `learning_rate`. (LR bajo -> N alto). | 100 - 5000 (con early stopping) |
| `num_leaves` (max_leaves) | Complejidad del 치rbol | Control principal de complejidad en LGBM. | 20 - 100 |
| `max_depth` | Profundidad m치xima | Limita `num_leaves`. 칔til para evitar overfitting extremo. | 3 - 12 |
| `subsample` (bagging_fraction) | % Datos por 치rbol | Previene overfitting. Acelera entrenamiento. | 0.5 - 0.9 |
| `colsample_bytree` (feature_fraction) | % Features por 치rbol | Previene overfitting. | 0.5 - 0.9 |
| `scale_pos_weight` | Peso clase positiva | **CR칈TICO** para desbalance. | sum(neg) / sum(pos) |

---

## 丘뒲잺 Gu칤a de Tuning R치pida

1.  **Overfitting (Train >>> Test):**
    *   拘勇 `max_depth` / `num_leaves`
    *   拘勇 `min_samples_leaf` / `min_child_weight`
    *   拘勇 `subsample` / `colsample_bytree`
    *   拘勇 `reg_alpha` (L1) / `reg_lambda` (L2)

2.  **Underfitting (Train bajo y Test bajo):**
    *   拘勇 `max_depth` / `num_leaves`
    *   拘勇 `learning_rate` (y aumentar `n_estimators`)
    *   拘勇 Regularizaci칩n

3.  **Velocidad:**
    *   Usar `LightGBM` en lugar de XGBoost.
    *   Usar GPU (`device='gpu'`).
    *   Aumentar `batch_size` (si aplica).
